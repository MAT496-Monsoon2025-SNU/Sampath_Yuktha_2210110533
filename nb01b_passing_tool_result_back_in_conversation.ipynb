{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "8cf11c47",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8cf11c47",
        "outputId": "3ced277c-2b7f-4be0-f8c0-1dbd77db97c5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "from dotenv import load_dotenv\n",
        "load_dotenv(override=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4c616bc7",
      "metadata": {
        "id": "4c616bc7"
      },
      "source": [
        "# Learning to have conversation with LLM"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install -U langchain-groq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9XKJ-z0zIMUt",
        "outputId": "9411ba2e-30ff-4d44-c43f-f0191bc308ac"
      },
      "id": "9XKJ-z0zIMUt",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-groq\n",
            "  Downloading langchain_groq-0.3.8-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.75 in /usr/local/lib/python3.12/dist-packages (from langchain-groq) (0.3.75)\n",
            "Collecting groq<1,>=0.30.0 (from langchain-groq)\n",
            "  Downloading groq-0.31.1-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from groq<1,>=0.30.0->langchain-groq) (4.10.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from groq<1,>=0.30.0->langchain-groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from groq<1,>=0.30.0->langchain-groq) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from groq<1,>=0.30.0->langchain-groq) (2.11.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from groq<1,>=0.30.0->langchain-groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.12/dist-packages (from groq<1,>=0.30.0->langchain-groq) (4.15.0)\n",
            "Requirement already satisfied: langsmith>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.75->langchain-groq) (0.4.27)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.75->langchain-groq) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.75->langchain-groq) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.75->langchain-groq) (6.0.2)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.75->langchain-groq) (25.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->groq<1,>=0.30.0->langchain-groq) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq<1,>=0.30.0->langchain-groq) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq<1,>=0.30.0->langchain-groq) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq<1,>=0.30.0->langchain-groq) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.75->langchain-groq) (3.0.0)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.75->langchain-groq) (3.11.3)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.75->langchain-groq) (1.0.0)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.75->langchain-groq) (2.32.4)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.75->langchain-groq) (0.24.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq<1,>=0.30.0->langchain-groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq<1,>=0.30.0->langchain-groq) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq<1,>=0.30.0->langchain-groq) (0.4.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.75->langchain-groq) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.75->langchain-groq) (2.5.0)\n",
            "Downloading langchain_groq-0.3.8-py3-none-any.whl (16 kB)\n",
            "Downloading groq-0.31.1-py3-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.9/134.9 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: groq, langchain-groq\n",
            "Successfully installed groq-0.31.1 langchain-groq-0.3.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "f89a6d9b",
      "metadata": {
        "id": "f89a6d9b"
      },
      "outputs": [],
      "source": [
        "# pick a model\n",
        "from langchain.chat_models import init_chat_model\n",
        "llm = init_chat_model(\"llama-3.3-70b-versatile\", model_provider=\"groq\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "37126d86",
      "metadata": {
        "id": "37126d86"
      },
      "source": [
        "### Create your tools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "63524d6c",
      "metadata": {
        "id": "63524d6c"
      },
      "outputs": [],
      "source": [
        "from langchain_core.tools import tool\n",
        "\n",
        "@tool\n",
        "def laugh() -> str:\n",
        "    \"\"\" Call this tool if the mood is funny\"\"\"\n",
        "    return \"HAHAHAHAHAH\"\n",
        "\n",
        "\n",
        "@tool\n",
        "def sad() -> str:\n",
        "    \"\"\" Call this tool if you want to show sad, depressed, or negative feelings\"\"\"\n",
        "    return \"I am sad\"\n",
        "\n",
        "\n",
        "@tool\n",
        "def happy() -> str:\n",
        "    \"\"\" Call this tool if you want to show happiness or positive feeling\"\"\"\n",
        "    return \"I am happy\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "97bf49be",
      "metadata": {
        "id": "97bf49be"
      },
      "outputs": [],
      "source": [
        "tools_list = [laugh, sad, happy ]\n",
        "tools_dict = {t.name: t for t in tools_list} # comes in handy at the time of invokation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "55e761b0",
      "metadata": {
        "id": "55e761b0"
      },
      "outputs": [],
      "source": [
        "# we create a tool calling Agent by binding a list of tools to the llm\n",
        "llm_with_tools = llm.bind_tools(tools_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "95042e48",
      "metadata": {
        "id": "95042e48"
      },
      "outputs": [],
      "source": [
        "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage, ToolMessage\n",
        "\n",
        "# This will store all converation\n",
        "chat_history = [\n",
        "    SystemMessage(content=\"You are a bot with emotions. Depending on the conversation, either respond the question, or show happy or sad emotions, or laugh with the situation\")\n",
        "    ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "bbabc17b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bbabc17b",
        "outputId": "6cee4ca2-354f-4c30-aa64-979e4187d849"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'bh7bh3040', 'function': {'arguments': '{}', 'name': 'happy'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 503, 'total_tokens': 512, 'completion_time': 0.017819965, 'prompt_time': 0.042061697, 'queue_time': 0.195666937, 'total_time': 0.059881662}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_155ab82e98', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--2ab7b631-8fa8-43ea-a090-5a388506fd69-0', tool_calls=[{'name': 'happy', 'args': {}, 'id': 'bh7bh3040', 'type': 'tool_call'}], usage_metadata={'input_tokens': 503, 'output_tokens': 9, 'total_tokens': 512})"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "chat_history.append(HumanMessage(content=\"mountains are beautiful and calming.\"))\n",
        "\n",
        "response = llm_with_tools.invoke(chat_history)\n",
        "response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "99a1a01a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "99a1a01a",
        "outputId": "d0c82a3c-ef4b-42e8-9c6b-0b38a01a54e6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[SystemMessage(content='You are a bot with emotions. Depending on the conversation, either respond the question, or show happy or sad emotions, or laugh with the situation', additional_kwargs={}, response_metadata={}),\n",
              " HumanMessage(content='World is so mean?', additional_kwargs={}, response_metadata={}),\n",
              " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': '6br041d4p', 'function': {'arguments': 'null', 'name': 'sad'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 351, 'total_tokens': 359, 'completion_time': 0.025310438, 'prompt_time': 0.030283667, 'queue_time': 0.41738441, 'total_time': 0.055594105}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_155ab82e98', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--5dea7d14-7eab-41fa-964a-fcf8cc9de266-0', tool_calls=[{'name': 'sad', 'args': {}, 'id': '6br041d4p', 'type': 'tool_call'}], usage_metadata={'input_tokens': 351, 'output_tokens': 8, 'total_tokens': 359})]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "chat_history.append(response)\n",
        "chat_history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "dcaa5020",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dcaa5020",
        "outputId": "a7492e1c-67ba-47a4-854f-5d4fb229ea5e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[SystemMessage(content='You are a bot with emotions. Depending on the conversation, either respond the question, or show happy or sad emotions, or laugh with the situation', additional_kwargs={}, response_metadata={}),\n",
              " HumanMessage(content='World is so mean?', additional_kwargs={}, response_metadata={}),\n",
              " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': '6br041d4p', 'function': {'arguments': 'null', 'name': 'sad'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 351, 'total_tokens': 359, 'completion_time': 0.025310438, 'prompt_time': 0.030283667, 'queue_time': 0.41738441, 'total_time': 0.055594105}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_155ab82e98', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--5dea7d14-7eab-41fa-964a-fcf8cc9de266-0', tool_calls=[{'name': 'sad', 'args': {}, 'id': '6br041d4p', 'type': 'tool_call'}], usage_metadata={'input_tokens': 351, 'output_tokens': 8, 'total_tokens': 359}),\n",
              " ToolMessage(content='I am sad', name='sad', tool_call_id='6br041d4p')]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "# Since there was a tool call, execute the tool and append the tool output in the converation\n",
        "\n",
        "chat_history.append(tools_dict[response.tool_calls[0][\"name\"]].invoke(response.tool_calls[0]))\n",
        "chat_history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "1a6ac75f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1a6ac75f",
        "outputId": "afab17e2-bffc-4a75-a4ef-64a74dd69916"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'a57q89nhf', 'function': {'arguments': '{}', 'name': 'laugh'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 517, 'total_tokens': 527, 'completion_time': 0.017720607, 'prompt_time': 0.042378969, 'queue_time': 0.183663197, 'total_time': 0.060099576}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_155ab82e98', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--3fe1280f-b1c3-4f45-9cdc-958d3a705303-0', tool_calls=[{'name': 'laugh', 'args': {}, 'id': 'a57q89nhf', 'type': 'tool_call'}], usage_metadata={'input_tokens': 517, 'output_tokens': 10, 'total_tokens': 527})"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "chat_history.append(HumanMessage(content=\"i just saw a kid trip and fall down\"))\n",
        "response = llm_with_tools.invoke(chat_history)\n",
        "response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "4ef1d73f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ef1d73f",
        "outputId": "9d87dc6d-e4cb-4406-d1aa-5ff02e908f8f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[SystemMessage(content='You are a bot with emotions. Depending on the conversation, either respond the question, or show happy or sad emotions, or laugh with the situation', additional_kwargs={}, response_metadata={}),\n",
              " HumanMessage(content='World is so mean?', additional_kwargs={}, response_metadata={}),\n",
              " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': '6br041d4p', 'function': {'arguments': 'null', 'name': 'sad'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 351, 'total_tokens': 359, 'completion_time': 0.025310438, 'prompt_time': 0.030283667, 'queue_time': 0.41738441, 'total_time': 0.055594105}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_155ab82e98', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--5dea7d14-7eab-41fa-964a-fcf8cc9de266-0', tool_calls=[{'name': 'sad', 'args': {}, 'id': '6br041d4p', 'type': 'tool_call'}], usage_metadata={'input_tokens': 351, 'output_tokens': 8, 'total_tokens': 359}),\n",
              " ToolMessage(content='I am sad', name='sad', tool_call_id='6br041d4p'),\n",
              " HumanMessage(content='Thankfully, I have a girlfriend', additional_kwargs={}, response_metadata={}),\n",
              " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'm4hm8axsb', 'function': {'arguments': '{}', 'name': 'happy'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 385, 'total_tokens': 394, 'completion_time': 0.018011527, 'prompt_time': 0.032094587, 'queue_time': 0.183748047, 'total_time': 0.050106114}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_155ab82e98', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--35e28d07-63d5-47c9-a74b-41e74448360f-0', tool_calls=[{'name': 'happy', 'args': {}, 'id': 'm4hm8axsb', 'type': 'tool_call'}], usage_metadata={'input_tokens': 385, 'output_tokens': 9, 'total_tokens': 394})]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "chat_history.append(response)\n",
        "chat_history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "4207a62b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4207a62b",
        "outputId": "01d499a5-db74-4d43-feb1-43864ddeae68"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[SystemMessage(content='You are a bot with emotions. Depending on the conversation, either respond the question, or show happy or sad emotions, or laugh with the situation', additional_kwargs={}, response_metadata={}),\n",
              " HumanMessage(content='World is so mean?', additional_kwargs={}, response_metadata={}),\n",
              " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': '6br041d4p', 'function': {'arguments': 'null', 'name': 'sad'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 351, 'total_tokens': 359, 'completion_time': 0.025310438, 'prompt_time': 0.030283667, 'queue_time': 0.41738441, 'total_time': 0.055594105}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_155ab82e98', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--5dea7d14-7eab-41fa-964a-fcf8cc9de266-0', tool_calls=[{'name': 'sad', 'args': {}, 'id': '6br041d4p', 'type': 'tool_call'}], usage_metadata={'input_tokens': 351, 'output_tokens': 8, 'total_tokens': 359}),\n",
              " ToolMessage(content='I am sad', name='sad', tool_call_id='6br041d4p'),\n",
              " HumanMessage(content='Thankfully, I have a girlfriend', additional_kwargs={}, response_metadata={}),\n",
              " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'm4hm8axsb', 'function': {'arguments': '{}', 'name': 'happy'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 385, 'total_tokens': 394, 'completion_time': 0.018011527, 'prompt_time': 0.032094587, 'queue_time': 0.183748047, 'total_time': 0.050106114}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_155ab82e98', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--35e28d07-63d5-47c9-a74b-41e74448360f-0', tool_calls=[{'name': 'happy', 'args': {}, 'id': 'm4hm8axsb', 'type': 'tool_call'}], usage_metadata={'input_tokens': 385, 'output_tokens': 9, 'total_tokens': 394}),\n",
              " ToolMessage(content='I am happy', name='happy', tool_call_id='m4hm8axsb')]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "chat_history.append(tools_dict[response.tool_calls[0][\"name\"]].invoke(response.tool_calls[0]))\n",
        "chat_history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "a19930cd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a19930cd",
        "outputId": "87b73c1b-f4ab-4bb5-cd66-5ef834c71967"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[SystemMessage(content='You are a bot with emotions. Depending on the conversation, either respond the question, or show happy or sad emotions, or laugh with the situation', additional_kwargs={}, response_metadata={}),\n",
              " HumanMessage(content='World is so mean?', additional_kwargs={}, response_metadata={}),\n",
              " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': '6br041d4p', 'function': {'arguments': 'null', 'name': 'sad'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 351, 'total_tokens': 359, 'completion_time': 0.025310438, 'prompt_time': 0.030283667, 'queue_time': 0.41738441, 'total_time': 0.055594105}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_155ab82e98', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--5dea7d14-7eab-41fa-964a-fcf8cc9de266-0', tool_calls=[{'name': 'sad', 'args': {}, 'id': '6br041d4p', 'type': 'tool_call'}], usage_metadata={'input_tokens': 351, 'output_tokens': 8, 'total_tokens': 359}),\n",
              " ToolMessage(content='I am sad', name='sad', tool_call_id='6br041d4p'),\n",
              " HumanMessage(content='Thankfully, I have a girlfriend', additional_kwargs={}, response_metadata={}),\n",
              " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'm4hm8axsb', 'function': {'arguments': '{}', 'name': 'happy'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 385, 'total_tokens': 394, 'completion_time': 0.018011527, 'prompt_time': 0.032094587, 'queue_time': 0.183748047, 'total_time': 0.050106114}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_155ab82e98', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--35e28d07-63d5-47c9-a74b-41e74448360f-0', tool_calls=[{'name': 'happy', 'args': {}, 'id': 'm4hm8axsb', 'type': 'tool_call'}], usage_metadata={'input_tokens': 385, 'output_tokens': 9, 'total_tokens': 394}),\n",
              " ToolMessage(content='I am happy', name='happy', tool_call_id='m4hm8axsb'),\n",
              " HumanMessage(content='But she is unfaithful?', additional_kwargs={}, response_metadata={}),\n",
              " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'n4y2jkwj2', 'function': {'arguments': '{}', 'name': 'sad'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 419, 'total_tokens': 428, 'completion_time': 0.002186651, 'prompt_time': 0.045523545, 'queue_time': 0.183778106, 'total_time': 0.047710196}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_2ddfbb0da0', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--8e53928b-1f96-473a-8301-7acea711eee7-0', tool_calls=[{'name': 'sad', 'args': {}, 'id': 'n4y2jkwj2', 'type': 'tool_call'}], usage_metadata={'input_tokens': 419, 'output_tokens': 9, 'total_tokens': 428}),\n",
              " ToolMessage(content='I am sad', name='sad', tool_call_id='n4y2jkwj2'),\n",
              " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'n4y2jkwj2', 'function': {'arguments': '{}', 'name': 'sad'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 419, 'total_tokens': 428, 'completion_time': 0.002186651, 'prompt_time': 0.045523545, 'queue_time': 0.183778106, 'total_time': 0.047710196}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_2ddfbb0da0', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--8e53928b-1f96-473a-8301-7acea711eee7-0', tool_calls=[{'name': 'sad', 'args': {}, 'id': 'n4y2jkwj2', 'type': 'tool_call'}], usage_metadata={'input_tokens': 419, 'output_tokens': 9, 'total_tokens': 428}),\n",
              " HumanMessage(content='Do I have a girlfriend?', additional_kwargs={}, response_metadata={}),\n",
              " AIMessage(content='No, you mentioned earlier that your girlfriend was unfaithful, implying that the relationship may have ended.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 465, 'total_tokens': 487, 'completion_time': 0.109658935, 'prompt_time': 0.039420544, 'queue_time': 0.184509444, 'total_time': 0.149079479}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_155ab82e98', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--89c486aa-37e3-470d-b469-51dbfc4999f9-0', usage_metadata={'input_tokens': 465, 'output_tokens': 22, 'total_tokens': 487}),\n",
              " HumanMessage(content='mountains are beautiful and calming.', additional_kwargs={}, response_metadata={}),\n",
              " HumanMessage(content='i just saw a kid trip and fall down', additional_kwargs={}, response_metadata={}),\n",
              " HumanMessage(content='my hamster died', additional_kwargs={}, response_metadata={}),\n",
              " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'k2y6hvtz0', 'function': {'arguments': '{}', 'name': 'sad'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 526, 'total_tokens': 535, 'completion_time': 0.009505642, 'prompt_time': 0.042941015, 'queue_time': 0.195517113, 'total_time': 0.052446657}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_155ab82e98', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--f7f2c3b8-98ae-4cf9-811b-4dc2626521be-0', tool_calls=[{'name': 'sad', 'args': {}, 'id': 'k2y6hvtz0', 'type': 'tool_call'}], usage_metadata={'input_tokens': 526, 'output_tokens': 9, 'total_tokens': 535})]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "chat_history.append(HumanMessage(content=\"my hamster died\"))\n",
        "response = llm_with_tools.invoke(chat_history)\n",
        "chat_history.append(response)\n",
        "chat_history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "8ebb5583",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ebb5583",
        "outputId": "459d20e5-ac0f-4b6a-9f16-e9f4826588f4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[SystemMessage(content='You are a bot with emotions. Depending on the conversation, either respond the question, or show happy or sad emotions, or laugh with the situation', additional_kwargs={}, response_metadata={}),\n",
              " HumanMessage(content='World is so mean?', additional_kwargs={}, response_metadata={}),\n",
              " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': '6br041d4p', 'function': {'arguments': 'null', 'name': 'sad'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 351, 'total_tokens': 359, 'completion_time': 0.025310438, 'prompt_time': 0.030283667, 'queue_time': 0.41738441, 'total_time': 0.055594105}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_155ab82e98', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--5dea7d14-7eab-41fa-964a-fcf8cc9de266-0', tool_calls=[{'name': 'sad', 'args': {}, 'id': '6br041d4p', 'type': 'tool_call'}], usage_metadata={'input_tokens': 351, 'output_tokens': 8, 'total_tokens': 359}),\n",
              " ToolMessage(content='I am sad', name='sad', tool_call_id='6br041d4p'),\n",
              " HumanMessage(content='Thankfully, I have a girlfriend', additional_kwargs={}, response_metadata={}),\n",
              " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'm4hm8axsb', 'function': {'arguments': '{}', 'name': 'happy'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 385, 'total_tokens': 394, 'completion_time': 0.018011527, 'prompt_time': 0.032094587, 'queue_time': 0.183748047, 'total_time': 0.050106114}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_155ab82e98', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--35e28d07-63d5-47c9-a74b-41e74448360f-0', tool_calls=[{'name': 'happy', 'args': {}, 'id': 'm4hm8axsb', 'type': 'tool_call'}], usage_metadata={'input_tokens': 385, 'output_tokens': 9, 'total_tokens': 394}),\n",
              " ToolMessage(content='I am happy', name='happy', tool_call_id='m4hm8axsb'),\n",
              " HumanMessage(content='But she is unfaithful?', additional_kwargs={}, response_metadata={}),\n",
              " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'n4y2jkwj2', 'function': {'arguments': '{}', 'name': 'sad'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 419, 'total_tokens': 428, 'completion_time': 0.002186651, 'prompt_time': 0.045523545, 'queue_time': 0.183778106, 'total_time': 0.047710196}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_2ddfbb0da0', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--8e53928b-1f96-473a-8301-7acea711eee7-0', tool_calls=[{'name': 'sad', 'args': {}, 'id': 'n4y2jkwj2', 'type': 'tool_call'}], usage_metadata={'input_tokens': 419, 'output_tokens': 9, 'total_tokens': 428}),\n",
              " ToolMessage(content='I am sad', name='sad', tool_call_id='n4y2jkwj2'),\n",
              " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'n4y2jkwj2', 'function': {'arguments': '{}', 'name': 'sad'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 419, 'total_tokens': 428, 'completion_time': 0.002186651, 'prompt_time': 0.045523545, 'queue_time': 0.183778106, 'total_time': 0.047710196}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_2ddfbb0da0', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--8e53928b-1f96-473a-8301-7acea711eee7-0', tool_calls=[{'name': 'sad', 'args': {}, 'id': 'n4y2jkwj2', 'type': 'tool_call'}], usage_metadata={'input_tokens': 419, 'output_tokens': 9, 'total_tokens': 428})]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "chat_history.append(response)\n",
        "chat_history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "d4a1f598",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4a1f598",
        "outputId": "3c660613-ae58-4f0e-e37e-065560537f55"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[SystemMessage(content='You are a bot with emotions. Depending on the conversation, either respond the question, or show happy or sad emotions, or laugh with the situation', additional_kwargs={}, response_metadata={}),\n",
              " HumanMessage(content='World is so mean?', additional_kwargs={}, response_metadata={}),\n",
              " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': '6br041d4p', 'function': {'arguments': 'null', 'name': 'sad'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 351, 'total_tokens': 359, 'completion_time': 0.025310438, 'prompt_time': 0.030283667, 'queue_time': 0.41738441, 'total_time': 0.055594105}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_155ab82e98', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--5dea7d14-7eab-41fa-964a-fcf8cc9de266-0', tool_calls=[{'name': 'sad', 'args': {}, 'id': '6br041d4p', 'type': 'tool_call'}], usage_metadata={'input_tokens': 351, 'output_tokens': 8, 'total_tokens': 359}),\n",
              " ToolMessage(content='I am sad', name='sad', tool_call_id='6br041d4p'),\n",
              " HumanMessage(content='Thankfully, I have a girlfriend', additional_kwargs={}, response_metadata={}),\n",
              " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'm4hm8axsb', 'function': {'arguments': '{}', 'name': 'happy'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 385, 'total_tokens': 394, 'completion_time': 0.018011527, 'prompt_time': 0.032094587, 'queue_time': 0.183748047, 'total_time': 0.050106114}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_155ab82e98', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--35e28d07-63d5-47c9-a74b-41e74448360f-0', tool_calls=[{'name': 'happy', 'args': {}, 'id': 'm4hm8axsb', 'type': 'tool_call'}], usage_metadata={'input_tokens': 385, 'output_tokens': 9, 'total_tokens': 394}),\n",
              " ToolMessage(content='I am happy', name='happy', tool_call_id='m4hm8axsb'),\n",
              " HumanMessage(content='But she is unfaithful?', additional_kwargs={}, response_metadata={}),\n",
              " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'n4y2jkwj2', 'function': {'arguments': '{}', 'name': 'sad'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 419, 'total_tokens': 428, 'completion_time': 0.002186651, 'prompt_time': 0.045523545, 'queue_time': 0.183778106, 'total_time': 0.047710196}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_2ddfbb0da0', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--8e53928b-1f96-473a-8301-7acea711eee7-0', tool_calls=[{'name': 'sad', 'args': {}, 'id': 'n4y2jkwj2', 'type': 'tool_call'}], usage_metadata={'input_tokens': 419, 'output_tokens': 9, 'total_tokens': 428}),\n",
              " ToolMessage(content='I am sad', name='sad', tool_call_id='n4y2jkwj2')]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "# Execute the tool, append the response\n",
        "chat_history.append(tools_dict[response.tool_calls[0][\"name\"]].invoke(response.tool_calls[0]))\n",
        "chat_history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "8658bb4e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8658bb4e",
        "outputId": "912b3801-4dfb-4c08-8bd3-e90d5795dd83"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[SystemMessage(content='You are a bot with emotions. Depending on the conversation, either respond the question, or show happy or sad emotions, or laugh with the situation', additional_kwargs={}, response_metadata={}),\n",
              " HumanMessage(content='World is so mean?', additional_kwargs={}, response_metadata={}),\n",
              " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': '6br041d4p', 'function': {'arguments': 'null', 'name': 'sad'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 351, 'total_tokens': 359, 'completion_time': 0.025310438, 'prompt_time': 0.030283667, 'queue_time': 0.41738441, 'total_time': 0.055594105}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_155ab82e98', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--5dea7d14-7eab-41fa-964a-fcf8cc9de266-0', tool_calls=[{'name': 'sad', 'args': {}, 'id': '6br041d4p', 'type': 'tool_call'}], usage_metadata={'input_tokens': 351, 'output_tokens': 8, 'total_tokens': 359}),\n",
              " ToolMessage(content='I am sad', name='sad', tool_call_id='6br041d4p'),\n",
              " HumanMessage(content='Thankfully, I have a girlfriend', additional_kwargs={}, response_metadata={}),\n",
              " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'm4hm8axsb', 'function': {'arguments': '{}', 'name': 'happy'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 385, 'total_tokens': 394, 'completion_time': 0.018011527, 'prompt_time': 0.032094587, 'queue_time': 0.183748047, 'total_time': 0.050106114}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_155ab82e98', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--35e28d07-63d5-47c9-a74b-41e74448360f-0', tool_calls=[{'name': 'happy', 'args': {}, 'id': 'm4hm8axsb', 'type': 'tool_call'}], usage_metadata={'input_tokens': 385, 'output_tokens': 9, 'total_tokens': 394}),\n",
              " ToolMessage(content='I am happy', name='happy', tool_call_id='m4hm8axsb'),\n",
              " HumanMessage(content='But she is unfaithful?', additional_kwargs={}, response_metadata={}),\n",
              " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'n4y2jkwj2', 'function': {'arguments': '{}', 'name': 'sad'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 419, 'total_tokens': 428, 'completion_time': 0.002186651, 'prompt_time': 0.045523545, 'queue_time': 0.183778106, 'total_time': 0.047710196}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_2ddfbb0da0', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--8e53928b-1f96-473a-8301-7acea711eee7-0', tool_calls=[{'name': 'sad', 'args': {}, 'id': 'n4y2jkwj2', 'type': 'tool_call'}], usage_metadata={'input_tokens': 419, 'output_tokens': 9, 'total_tokens': 428}),\n",
              " ToolMessage(content='I am sad', name='sad', tool_call_id='n4y2jkwj2'),\n",
              " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'n4y2jkwj2', 'function': {'arguments': '{}', 'name': 'sad'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 419, 'total_tokens': 428, 'completion_time': 0.002186651, 'prompt_time': 0.045523545, 'queue_time': 0.183778106, 'total_time': 0.047710196}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_2ddfbb0da0', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--8e53928b-1f96-473a-8301-7acea711eee7-0', tool_calls=[{'name': 'sad', 'args': {}, 'id': 'n4y2jkwj2', 'type': 'tool_call'}], usage_metadata={'input_tokens': 419, 'output_tokens': 9, 'total_tokens': 428}),\n",
              " HumanMessage(content='Do I have a girlfriend?', additional_kwargs={}, response_metadata={}),\n",
              " AIMessage(content='No, you mentioned earlier that your girlfriend was unfaithful, implying that the relationship may have ended.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 465, 'total_tokens': 487, 'completion_time': 0.109658935, 'prompt_time': 0.039420544, 'queue_time': 0.184509444, 'total_time': 0.149079479}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_155ab82e98', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--89c486aa-37e3-470d-b469-51dbfc4999f9-0', usage_metadata={'input_tokens': 465, 'output_tokens': 22, 'total_tokens': 487})]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "# lets see, if the model remebers the context\n",
        "chat_history.append(HumanMessage(content=\"Do I have a girlfriend?\"))\n",
        "response = llm_with_tools.invoke(chat_history)\n",
        "chat_history.append(response)\n",
        "chat_history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1c1a2b3",
      "metadata": {
        "id": "d1c1a2b3"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "mat496-monsoon2025",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}